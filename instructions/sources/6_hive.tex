\documentclass{article}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{polski}
\usepackage[polish]{babel}
\usepackage{listings}
\usepackage[T1]{fontenc}

\pagenumbering{gobble}
\lstset{
	language=sql,
	frame=single,
	basicstyle=\tiny,
	literate=*{-}{-}1,
	columns=fullflexible
	}
	
\begin{document}
\section*{Hive}

Dokumentacja Hive:
\\*
https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML
\\*
\\*
Połączenie beeline:
\begin{lstlisting}
!connect jdbc:hive2://<host>:<port>/<baza> <user> <haslo>
!connect jdbc:hive2://<adminsk02...>:10000 jpodeszwik jpodeszwik
!connect jdbc:hive2://<adminsk02...>:10000/xyz jpodeszwik jpodeszwik
\end{lstlisting}

Utworzenie bazy
\begin{lstlisting}
create database xyz;
\end{lstlisting}

Przełączenie bazy
\begin{lstlisting}
use xyz;
\end{lstlisting}

Utworzenie tabeli i załadowanie danych:
\begin{lstlisting}
CREATE TABLE transfers(
		src STRING,
		dst STRING,
		amount INT,
		date STRING
	)
	ROW FORMAT DELIMITED
	FIELDS TERMINATED BY ","
	STORED AS TEXTFILE;

LOAD DATA INPATH "/user/vagrant/transfers" INTO TABLE transfers;
\end{lstlisting}

Utworzenie tabeli w konkretnej lokalizacji (która może już istnieć):
\begin{lstlisting}
CREATE TABLE transfers2(
		src STRING,
		dst STRING,
		amount INT,
		date STRING
	)
	ROW FORMAT DELIMITED
	FIELDS TERMINATED BY ","
	STORED AS TEXTFILE
	LOCATION "/user/xyz/transfers_table";
\end{lstlisting}

Utworzenie tabeli external:
\begin{lstlisting}
CREATE EXTERNAL TABLE transfers3 <reszta_polecenia>;
\end{lstlisting}

Zmiana delimitera:
\begin{lstlisting}
create table transfers4
row format delimited
fields terminated by ";"
as select * from transfers;
\end{lstlisting}

Zmiana formatu danych:
\begin{lstlisting}
create table transfers5
stored as orc
as select * from transfers;
\end{lstlisting}

Włączenie kompresji:
\begin{lstlisting}
set hive.exec.compress.output=true;
set mapreduce.output.fileoutputformat.compress=true;
set mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.GzipCodec;
set mapreduce.output.fileoutputformat.compress.type=BLOCK;
\end{lstlisting}

Odblokowanie dynamicznego wyznaczania partycji:
\begin{lstlisting}
SET hive.exec.dynamic.partition=true;
\end{lstlisting}

\pagebreak

Odświeżenie danych o partycjach:
\begin{lstlisting}
MSCK REPAIR TABLE <tabela>;
\end{lstlisting}

\begin{lstlisting}
CREATE TABLE transfers5(
		src STRING,
		dst STRING,
		amount INT,
		date STRING
	)
	partitioned by (log_time string)
	ROW FORMAT DELIMITED
	FIELDS TERMINATED BY ","
	STORED AS TEXTFILE
	LOCATION "/user/xyz/events";
\end{lstlisting}

Wyświetlenie danych na temat tabeli:
\begin{lstlisting}
show create table transfers;
\end{lstlisting}

\subsection*{Zadania}

\begin{enumerate}
\item Zaloguj się na hue. Utwórz sobie użytkownika '<login>' i korzystaj z niego w dalszych poleceniach.
\item Utwórz bazę <login> i używaj jej przy dalszych poleceniach.
\item Utwórz tabelę transfers. Wrzuć do niej dane z pliku transfers.
\item Utwórz tabelę typu ‘external’ i załaduj do niej takie same dane.
\item Zdropuj obie tabele i zobacz co stało się z danymi na hdfsie.
\item Utwórz tabelę w formacie ORC. Spróbuj poleceniem ‘hdfs dfs -cat ...’ wypisać zawartość plików i zobacz, że są binarne.
\item Posumuj pole 'amount' po koncie źródłowym.
\item Utwórz tabelę 'owners' z logów załadowanych sqoopem
\item Utwórz tabelę 'named\_transfers' będącą wynikiem zjoinowania tabel 'owners' i 'transfers', tzn zamiast src i dst będzie zawierać pola from i to w których będą imiona.
\item Utwórz tabelę partycjonowaną po id konta źródłowego.
\item Utwórz tabelę partycjonowaną po log\_time z katalogów, które wrzucił Flume.
\end{enumerate}

\end{document}
